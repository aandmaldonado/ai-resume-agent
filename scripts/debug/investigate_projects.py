#!/usr/bin/env python3
"""
üîç INVESTIGACI√ìN ESPEC√çFICA - Chunks de Proyectos
Script para investigar por qu√© los chunks de proyectos no se recuperan
"""

import asyncio
import os
import sys
from pathlib import Path

# A√±adir el directorio del proyecto al path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# Cargar variables de entorno desde archivo .env
from dotenv import load_dotenv
load_dotenv()

from app.services.rag_service import RAGService

async def investigate_projects():
    """Investigar espec√≠ficamente los chunks de proyectos"""
    print("üîç INVESTIGACI√ìN ESPEC√çFICA - CHUNKS DE PROYECTOS")
    print("=" * 60)
    
    try:
        # Inicializar RAG Service
        print("üîÑ Inicializando RAG Service...")
        rag_service = RAGService()
        print("‚úÖ RAG Service inicializado")
        
        # Preguntas espec√≠ficas sobre proyectos
        project_questions = [
            "¬øQu√© proyectos de IA has liderado?",
            "AcuaMattic",
            "proyectos de inteligencia artificial",
            "¬øCu√°l fue el logro m√°s significativo en AcuaMattic?",
            "proyectos",
            "IA",
            "machine learning",
            "TensorFlow",
            "PyTorch",
        ]
        
        print(f"\nüß™ Probando {len(project_questions)} consultas sobre proyectos...")
        
        for question in project_questions:
            print(f"\nüìã Consulta: '{question}'")
            
            # Obtener contexto relevante
            retriever = rag_service.vector_store.as_retriever(
                search_kwargs={"k": 10}  # Aumentar k para ver m√°s resultados
            )
            docs = retriever.get_relevant_documents(question)
            
            print(f"üìö Chunks encontrados: {len(docs)}")
            
            # Contar por source
            sources = {}
            for doc in docs:
                source = doc.metadata.get("source", "unknown")
                sources[source] = sources.get(source, 0) + 1
            
            print(f"üìä Distribuci√≥n por source: {sources}")
            
            # Mostrar chunks de proyectos si los hay
            project_docs = [doc for doc in docs if doc.metadata.get("source") == "project"]
            if project_docs:
                print(f"‚úÖ Encontrados {len(project_docs)} chunks de proyectos:")
                for i, doc in enumerate(project_docs[:2]):  # Mostrar solo los primeros 2
                    project_id = doc.metadata.get("id", "unknown")
                    preview = doc.page_content[:150] + "..." if len(doc.page_content) > 150 else doc.page_content
                    print(f"   {i+1}. Project ID: {project_id}")
                    print(f"      Preview: {preview}")
            else:
                print("   ‚ùå No se encontraron chunks de proyectos")
            
            print("-" * 40)
        
        # Verificar directamente en la base de datos
        print(f"\nüîç Verificaci√≥n directa en la base de datos...")
        
        # Consulta directa para contar chunks por source
        from app.core.config import settings
        import psycopg2
        
        conn = psycopg2.connect(settings.database_url)
        cursor = conn.cursor()
        
        # Contar chunks por source
        cursor.execute("""
            SELECT cmetadata->>'source' as source, COUNT(*) as count
            FROM langchain_pg_embedding 
            WHERE collection_id = (
                SELECT uuid FROM langchain_pg_collection WHERE name = %s
            )
            GROUP BY cmetadata->>'source'
            ORDER BY count DESC
        """, (settings.VECTOR_COLLECTION_NAME,))
        
        results = cursor.fetchall()
        print("üìä Chunks por source en la base de datos:")
        for source, count in results:
            print(f"   {source}: {count} chunks")
        
        # Verificar espec√≠ficamente chunks de proyectos
        cursor.execute("""
            SELECT cmetadata->>'id' as project_id, 
                   LEFT(document, 100) as preview
            FROM langchain_pg_embedding 
            WHERE collection_id = (
                SELECT uuid FROM langchain_pg_collection WHERE name = %s
            )
            AND cmetadata->>'source' = 'project'
            LIMIT 5
        """, (settings.VECTOR_COLLECTION_NAME,))
        
        project_results = cursor.fetchall()
        print(f"\nüìã Chunks de proyectos en la base de datos ({len(project_results)} encontrados):")
        for project_id, preview in project_results:
            print(f"   Project ID: {project_id}")
            print(f"   Preview: {preview}...")
        
        cursor.close()
        conn.close()
        
        print("\n‚úÖ Investigaci√≥n completada")
        
    except Exception as e:
        print(f"‚ùå Error en investigaci√≥n: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(investigate_projects())
