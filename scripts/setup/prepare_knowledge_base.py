"""
Script para procesar portfolio.yaml en documentos sem√°nticos para RAG.
Convierte el YAML en chunks optimizados para embeddings y retrieval.
"""
from pathlib import Path
from typing import List

import yaml
from langchain.docstore.document import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter


def process_portfolio_to_chunks(portfolio_path: str) -> List[Document]:
    """
    Procesa el archivo portfolio.yaml y lo convierte en chunks sem√°nticos.

    Args:
        portfolio_path: Ruta al archivo portfolio.yaml

    Returns:
        Lista de documentos LangChain listos para embeddings
    """
    # Leer YAML
    with open(portfolio_path, "r", encoding="utf-8") as f:
        data = yaml.safe_load(f)

    documents = []

    # 1. Informaci√≥n Personal
    personal = data.get("personal_info", {})
    if personal:
        content = f"""
Informaci√≥n Personal:
Nombre: {personal.get('name', 'N/A')}
T√≠tulo: {personal.get('title', 'N/A')}
Email: {personal.get('email', 'N/A')}
Ubicaci√≥n: {personal.get('location', 'N/A')}
LinkedIn: {personal.get('linkedin', 'N/A')}
GitHub: {personal.get('github', 'N/A')}
Sitio Web: {personal.get('website', 'N/A')}
"""
        documents.append(
            Document(
                page_content=content.strip(),
                metadata={"type": "personal_info", "source": "portfolio.yaml"},
            )
        )

    # 2. Resumen Profesional
    prof_summary = data.get("professional_summary", {})
    if prof_summary:
        short_summary = prof_summary.get("short", "")
        detailed_summary = prof_summary.get("detailed", "")

        content = f"""
Resumen Profesional:

{short_summary}

{detailed_summary}
"""
        documents.append(
            Document(
                page_content=content.strip(),
                metadata={"type": "professional_summary", "source": "portfolio.yaml"},
            )
        )

    # 3. Experiencia Laboral (cada empresa es un documento)
    for exp in data.get("experience", []):
        company = exp.get("company", "N/A")
        position = exp.get("position", "N/A")
        duration = exp.get("duration", "N/A")
        location = exp.get("location", "N/A")
        description = exp.get("description", "N/A")
        technologies = ", ".join(exp.get("technologies", []))
        projects = ", ".join(exp.get("related_projects", []))

        content = f"""
Experiencia Laboral:

Empresa: {company}
Posici√≥n: {position}
Duraci√≥n: {duration}
Ubicaci√≥n: {location}

Descripci√≥n:
{description}

Tecnolog√≠as utilizadas: {technologies}

Proyectos relacionados: {projects}
"""
        documents.append(
            Document(
                page_content=content.strip(),
                metadata={
                    "type": "experience",
                    "company": company,
                    "position": position,
                    "duration": duration,
                    "source": "portfolio.yaml",
                },
            )
        )

    # 4. Educaci√≥n (cada t√≠tulo es un documento)
    for edu in data.get("education", []):
        institution = edu.get("institution", "N/A")
        degree = edu.get("degree", "N/A")
        period = edu.get("period", "N/A")
        details = edu.get("details", "")
        knowledge = edu.get("knowledge_acquired", [])

        knowledge_list = "\n".join([f"- {k}" for k in knowledge])

        content = f"""
Educaci√≥n:

Instituci√≥n: {institution}
T√≠tulo: {degree}
Periodo: {period}

{details}

Conocimientos adquiridos:
{knowledge_list}
"""
        documents.append(
            Document(
                page_content=content.strip(),
                metadata={
                    "type": "education",
                    "institution": institution,
                    "degree": degree,
                    "period": period,
                    "source": "portfolio.yaml",
                },
            )
        )

    # 5. Skills por categor√≠a
    for skill_cat in data.get("skills", []):
        category = skill_cat.get("category", "N/A")
        items = ", ".join(skill_cat.get("items", []))

        content = f"""
Habilidades T√©cnicas:

Categor√≠a: {category}

Habilidades: {items}
"""
        documents.append(
            Document(
                page_content=content.strip(),
                metadata={
                    "type": "skills",
                    "category": category,
                    "source": "portfolio.yaml",
                },
            )
        )

    # 6. Proyectos Destacados
    for project in data.get("projects", []):
        name = project.get("name", "N/A")
        company = project.get("company", "N/A")
        description = project.get("description", "N/A")
        technologies = ", ".join(project.get("technologies", []))

        content = f"""
Proyecto Destacado:

Nombre: {name}
Empresa: {company}

Descripci√≥n:
{description}

Tecnolog√≠as utilizadas: {technologies}
"""
        documents.append(
            Document(
                page_content=content.strip(),
                metadata={
                    "type": "project",
                    "name": name,
                    "company": company,
                    "source": "portfolio.yaml",
                },
            )
        )

    # 7. Idiomas
    for lang in data.get("languages", []):
        name = lang.get("name", "N/A")
        level = lang.get("level", "N/A")

        content = f"""
Idioma: {name}
Nivel: {level}
"""
        documents.append(
            Document(
                page_content=content.strip(),
                metadata={
                    "type": "language",
                    "language": name,
                    "level": level,
                    "source": "portfolio.yaml",
                },
            )
        )

    # 8. Disponibilidad
    availability = data.get("availability", {})
    if availability:
        status = availability.get("status", "N/A")
        notice_period = availability.get("notice_period", "N/A")
        remote_work = availability.get("remote_work", "N/A")

        content = f"""
Disponibilidad:

Estado: {status}
Periodo de aviso: {notice_period}
Trabajo remoto: {remote_work}
"""
        documents.append(
            Document(
                page_content=content.strip(),
                metadata={"type": "availability", "source": "portfolio.yaml"},
            )
        )

    # 9. Filosof√≠a e Intereses
    for interest in data.get("philosophy_and_interests", []):
        title = interest.get("title", "N/A")
        description = interest.get("description", "N/A")

        content = f"""
Filosof√≠a e Intereses:

{title}:
{description}
"""
        documents.append(
            Document(
                page_content=content.strip(),
                metadata={
                    "type": "philosophy",
                    "title": title,
                    "source": "portfolio.yaml",
                },
            )
        )

    # 10. Contexto del chatbot (personalidad)
    chatbot_context = data.get("chatbot_context", {})
    if chatbot_context:
        personality = chatbot_context.get("personality", "N/A")
        tone = chatbot_context.get("tone", "N/A")
        expertise_areas = ", ".join(chatbot_context.get("expertise_areas", []))

        content = f"""
Personalidad del Profesional:

Personalidad: {personality}
Tono de comunicaci√≥n: {tone}
√Åreas de expertise: {expertise_areas}
"""
        documents.append(
            Document(
                page_content=content.strip(),
                metadata={"type": "personality", "source": "portfolio.yaml"},
            )
        )

    # Crear chunks sem√°nticos con overlap para mejor retrieval
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,  # Tama√±o √≥ptimo para embeddings
        chunk_overlap=50,  # Overlap para mantener contexto
        length_function=len,
        separators=["\n\n", "\n", ". ", " ", ""],
    )

    chunks = text_splitter.split_documents(documents)

    return chunks


def save_chunks_summary(
    chunks: List[Document], output_path: str = "data/chunks_summary.txt"
):
    """
    Guarda un resumen de los chunks generados para inspecci√≥n.

    Args:
        chunks: Lista de documentos chunk
        output_path: Ruta donde guardar el resumen
    """
    output_file = Path(output_path)
    output_file.parent.mkdir(parents=True, exist_ok=True)

    with open(output_file, "w", encoding="utf-8") as f:
        f.write(f"Total de chunks generados: {len(chunks)}\n\n")
        f.write("=" * 80 + "\n\n")

        for i, chunk in enumerate(chunks, 1):
            f.write(f"CHUNK #{i}\n")
            f.write(f"Metadata: {chunk.metadata}\n")
            f.write(f"Content:\n{chunk.page_content}\n")
            f.write("=" * 80 + "\n\n")

    print(f"‚úì Resumen guardado en: {output_path}")


if __name__ == "__main__":
    # Test del script
    portfolio_path = "data/portfolio.yaml"

    if not Path(portfolio_path).exists():
        print(f"‚ùå Error: No se encontr√≥ {portfolio_path}")
        exit(1)

    print(f"üìÑ Procesando {portfolio_path}...")
    chunks = process_portfolio_to_chunks(portfolio_path)

    print(f"‚úì {len(chunks)} chunks generados")

    # Mostrar estad√≠sticas
    types = {}
    for chunk in chunks:
        chunk_type = chunk.metadata.get("type", "unknown")
        types[chunk_type] = types.get(chunk_type, 0) + 1

    print("\nüìä Distribuci√≥n por tipo:")
    for chunk_type, count in sorted(types.items()):
        print(f"  - {chunk_type}: {count} chunks")

    # Guardar resumen
    save_chunks_summary(chunks)
    print("\n‚úÖ Preparaci√≥n de datos completada")
