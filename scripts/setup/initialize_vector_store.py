"""
Script para inicializar el vector store en pgvector con los chunks del portfolio.
Ejecutar una sola vez para cargar la base de conocimientos.
"""
import os
import sys
import asyncio
from pathlib import Path

# A√±adir el directorio ra√≠z al path para imports
sys.path.insert(0, str(Path(__file__).parent.parent))

from dotenv import load_dotenv
from langchain_community.vectorstores import PGVector
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.docstore.document import Document

# Importaci√≥n opcional para evitar errores en producci√≥n
# Intentar importar desde el mismo directorio primero
load_and_prepare_chunks = None  # type: ignore
BUILD_KNOWLEDGE_BASE_AVAILABLE = False

try:
    # Intentar importar desde el mismo directorio (scripts/setup/)
    from scripts.setup.build_knowledge_base import load_and_prepare_chunks  # type: ignore
    BUILD_KNOWLEDGE_BASE_AVAILABLE = True
except ImportError:
    try:
        # Intentar importar sin el path completo
        from build_knowledge_base import load_and_prepare_chunks  # type: ignore
        BUILD_KNOWLEDGE_BASE_AVAILABLE = True
    except ImportError:
        BUILD_KNOWLEDGE_BASE_AVAILABLE = False
        print("‚ö†Ô∏è build_knowledge_base no disponible - funcionando en modo limitado")


def get_connection_string() -> str:
    """
    Construye el connection string para PostgreSQL desde variables de entorno.

    Returns:
        Connection string para psycopg2
    """
    # Para Cloud Run con Cloud SQL Proxy
    if os.getenv("CLOUD_SQL_CONNECTION_NAME"):
        # Conexi√≥n Unix socket para Cloud Run
        connection_name = os.getenv("CLOUD_SQL_CONNECTION_NAME")
        db_name = os.getenv("CLOUD_SQL_DB", "chatbot_db")
        db_user = os.getenv("CLOUD_SQL_USER", "postgres")
        db_password = os.getenv("CLOUD_SQL_PASSWORD")

        connection_string = (
            f"postgresql://{db_user}:{db_password}@/"
            f"{db_name}?host=/cloudsql/{connection_name}"
        )
    else:
        # Conexi√≥n directa (para desarrollo local)
        db_host = os.getenv("CLOUD_SQL_HOST", "localhost")
        db_port = os.getenv("CLOUD_SQL_PORT", "5432")
        db_name = os.getenv("CLOUD_SQL_DB", "chatbot_db")
        db_user = os.getenv("CLOUD_SQL_USER", "postgres")
        db_password = os.getenv("CLOUD_SQL_PASSWORD")

        connection_string = (
            f"postgresql://{db_user}:{db_password}@" f"{db_host}:{db_port}/{db_name}"
        )

    return connection_string


def initialize_vector_store_script():
    """
    Inicializa el vector store en pgvector con los chunks del portfolio.
    """
    print("üöÄ Inicializando vector store...\n")

    print("üìÑ Procesando portfolio.yaml desde archivo local...")

    # 2. Procesar portfolio en chunks
    try:
        # Usar el nuevo script con Hyper-Enrichment v2 si est√° disponible
        if BUILD_KNOWLEDGE_BASE_AVAILABLE and load_and_prepare_chunks:
            yaml_path = os.path.join(os.path.dirname(__file__), '..', '..', 'data', 'portfolio.yaml')
            chunks = load_and_prepare_chunks(yaml_path)
            if not chunks:
                raise Exception("No se pudieron generar chunks")
            print(f"‚úì {len(chunks)} chunks generados\n")
        else:
            print("‚ö†Ô∏è build_knowledge_base no disponible - saltando generaci√≥n de chunks")
            return True  # Retornar True para evitar errores en producci√≥n
    except Exception as e:
        print(f"‚ùå Error procesando portfolio: {e}")
        return False

    # 3. Inicializar embeddings locales (100% gratis, sin APIs)
    print("üîß Configurando HuggingFace Embeddings (local)...")
    try:
        # Usar modelo local de HuggingFace - no requiere API ni internet
        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
            model_kwargs={"device": "cpu"},
            encode_kwargs={"normalize_embeddings": True},
        )
        print("‚úì Embeddings configurados (modelo local)\n")
    except Exception as e:
        print(f"‚ùå Error configurando embeddings: {e}")
        print("   Aseg√∫rate de tener configuradas las credenciales de GCP")
        return False

    # 4. Obtener connection string
    print("üîß Configurando conexi√≥n a Cloud SQL...")
    try:
        connection_string = get_connection_string()
        print("‚úì Connection string configurado\n")
    except Exception as e:
        print(f"‚ùå Error configurando conexi√≥n: {e}")
        return False

    # 5. Crear vector store en pgvector
    print("üíæ Guardando chunks en pgvector...")
    print(f"   Esto puede tardar varios minutos ({len(chunks)} chunks)...\n")

    try:
        vector_store = PGVector.from_documents(
            documents=chunks,
            embedding=embeddings,
            connection_string=connection_string,
            collection_name="portfolio_knowledge",
            pre_delete_collection=True,  # Limpia colecci√≥n existente
        )
        print(f"‚úÖ Vector store inicializado exitosamente!")
        print(f"   - {len(chunks)} chunks guardados")
        print(f"   - Colecci√≥n: portfolio_knowledge")
        print(f"   - Base de datos: {os.getenv('CLOUD_SQL_DB', 'chatbot_db')}\n")

        return True

    except Exception as e:
        print(f"‚ùå Error guardando en pgvector: {e}")
        print("\nVerifica:")
        print("  1. Cloud SQL est√° corriendo y accesible")
        print("  2. La extensi√≥n pgvector est√° instalada")
        print("  3. Las credenciales son correctas")
        print("  4. El firewall permite la conexi√≥n")
        return False


def test_vector_store():
    """
    Prueba que el vector store funciona correctamente con una consulta de test.
    """
    print("\nüß™ Probando vector store con consulta de test...\n")

    try:
        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
            model_kwargs={"device": "cpu"},
            encode_kwargs={"normalize_embeddings": True},
        )

        connection_string = get_connection_string()

        vector_store = PGVector(
            connection_string=connection_string,
            embedding_function=embeddings,
            collection_name="portfolio_knowledge",
        )

        # Consulta de prueba
        test_query = "¬øCu√°l es tu experiencia profesional?"
        results = vector_store.similarity_search(test_query, k=3)

        print(f"‚úì Consulta de test: '{test_query}'")
        print(f"‚úì Resultados encontrados: {len(results)}\n")

        for i, doc in enumerate(results, 1):
            print(f"Resultado #{i}:")
            print(f"  Tipo: {doc.metadata.get('type', 'N/A')}")
            print(f"  Preview: {doc.page_content[:100]}...")
            print()

        print("‚úÖ Vector store funcionando correctamente!\n")
        return True

    except Exception as e:
        print(f"‚ùå Error en test: {e}\n")
        return False


if __name__ == "__main__":
    # Cargar variables de entorno
    load_dotenv()

    # Verificar variables de entorno cr√≠ticas
    required_vars = [
        "GCP_PROJECT_ID",
        "CLOUD_SQL_DB",
        "CLOUD_SQL_USER",
        "CLOUD_SQL_PASSWORD",
    ]
    missing_vars = [var for var in required_vars if not os.getenv(var)]

    if missing_vars:
        print("‚ùå Faltan variables de entorno:")
        for var in missing_vars:
            print(f"   - {var}")
        print("\nConfigura las variables en .env o como variables de entorno")
        sys.exit(1)

    print("=" * 80)
    print("INICIALIZACI√ìN DEL VECTOR STORE")
    print("=" * 80 + "\n")

    # Inicializar
    success = initialize_vector_store_script()

    if success:
        # Probar
        test_vector_store()
        print("=" * 80)
        print("‚úÖ PROCESO COMPLETADO EXITOSAMENTE")
        print("=" * 80)
    else:
        print("=" * 80)
        print("‚ùå PROCESO FALL√ì - Revisa los errores arriba")
        print("=" * 80)
        sys.exit(1)


async def initialize_vector_store(chunks: list[Document]) -> bool:
    """
    Funci√≥n async para inicializar el vector store con chunks dados.
    
    Args:
        chunks: Lista de documentos para cargar en el vector store
        
    Returns:
        bool: True si la inicializaci√≥n fue exitosa, False en caso contrario
    """
    try:
        print("üöÄ Inicializando vector store...")
        
        # Verificar variables de entorno
        required_vars = [
            "GCP_PROJECT_ID",
            "CLOUD_SQL_DB", 
            "CLOUD_SQL_USER",
            "CLOUD_SQL_PASSWORD"
        ]
        
        missing_vars = [var for var in required_vars if not os.getenv(var)]
        if missing_vars:
            print(f"‚ùå Faltan variables de entorno: {', '.join(missing_vars)}")
            return False
        
        # Configurar embeddings
        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
        )
        
        # Obtener connection string
        connection_string = get_connection_string()
        
        # Crear vector store
        vector_store = PGVector(
            connection_string=connection_string,
            embedding_function=embeddings,
            collection_name="portfolio_chunks"
        )
        
        # Limpiar colecci√≥n existente
        print("üßπ Limpiando colecci√≥n existente...")
        vector_store.delete_collection()
        
        # Cargar chunks
        print(f"üìö Cargando {len(chunks)} chunks enriquecidos...")
        vector_store.add_documents(chunks)
        
        print("‚úÖ Vector store inicializado exitosamente")
        return True
        
    except Exception as e:
        print(f"‚ùå Error inicializando vector store: {e}")
        return False
