# ü§ñ AI Resume Agent

Chatbot RAG (Retrieval Augmented Generation) para portfolio profesional. Responde preguntas sobre experiencia, habilidades y proyectos usando tecnolog√≠as **econ√≥micas** en la nube.

## üéØ Problema vs Soluci√≥n

### **Problema**
- Los portfolios est√°ticos no permiten interacci√≥n din√°mica con los visitantes
- Los reclutadores necesitan hacer preguntas espec√≠ficas sobre experiencia y proyectos
- Falta de engagement y personalizaci√≥n en la presentaci√≥n profesional

### **Soluci√≥n**
- **Chatbot inteligente** que responde preguntas sobre experiencia profesional
- **RAG avanzado** con embeddings locales y b√∫squeda sem√°ntica
- **Bajo costo** usando free tiers y servicios econ√≥micos de Google Cloud
- **Ultra r√°pido** con respuestas en 1-2 segundos

## üèóÔ∏è Arquitectura

```mermaid
graph TB
    A[Cliente Web] -->|HTTP/REST| B[FastAPI Backend]
    B --> C[RAG Pipeline]
    C --> D[HuggingFace Embeddings]
    C --> E[pgvector Search]
    C --> F[Gemini 2.5 Flash]
    D --> G[Cloud SQL PostgreSQL]
    E --> G
    F --> H[Response Generation]
    H --> A
    
    I[portfolio.yaml] --> J[Vector Store]
    J --> G
    
    subgraph "Cloud Run (europe-west1)"
        B
        C
    end
    
    subgraph "Knowledge Base"
        I
        J
    end
```

## üöÄ Quick Start

### Prerrequisitos
- **Python 3.11**
- Cuenta de Google Cloud Platform
- Cuenta de Google con Gemini API habilitada

### 1. Setup de Infraestructura
```bash
# Clonar y configurar
git clone https://github.com/tu-usuario/ai-resume-agent.git
cd ai-resume-agent

# Autenticar en GCP
gcloud auth login
gcloud config set project YOUR_PROJECT_ID

# Setup autom√°tico
chmod +x scripts/setup/setup-gcp.sh
./scripts/setup/setup-gcp.sh
```

### 2. Configurar Variables de Entorno
```bash
# Editar .env
nano .env

# Agregar:
GEMINI_API_KEY=AI...  # Obtener en aistudio.google.com/app/apikey
```

### 3. Inicializar Vector Store
```bash
# Crear entorno virtual
python3.11 -m venv venv
source venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt

# Procesar portfolio y cargar a pgvector
python scripts/setup/initialize_vector_store.py
```

### 4. Deploy Autom√°tico
```bash
# Push autom√°tico ‚Üí Cloud Build ‚Üí Deploy
git add .
git commit -m "feat: initial deployment"
git push origin main
```

### 5. Probar el Chatbot
```bash
# Obtener URL del servicio
gcloud run services describe chatbot-api --region europe-west1 --format 'value(status.url)'

# Test con curl
curl -X POST https://your-url/api/v1/chat \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $(gcloud auth print-identity-token)" \
  -d '{"message":"¬øCu√°l es tu experiencia profesional?"}'
```

## üìÅ Estructura del Proyecto

```
ai-resume-agent/
‚îú‚îÄ‚îÄ app/                          # Backend FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ main.py                  # Aplicaci√≥n principal
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py            # Configuraci√≥n centralizada
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ secrets.py           # Gesti√≥n de secretos
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rag_service.py       # Servicio RAG principal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analytics_service.py # Analytics y m√©tricas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ flow_controller.py   # Control de flujo conversacional
‚îÇ   ‚îú‚îÄ‚îÄ api/v1/endpoints/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat.py              # Endpoint /chat
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ analytics.py         # Endpoint /analytics
‚îÇ   ‚îú‚îÄ‚îÄ models/                  # Modelos de base de datos
‚îÇ   ‚îî‚îÄ‚îÄ schemas/                 # Modelos Pydantic
‚îÇ
‚îú‚îÄ‚îÄ scripts/                      # Scripts organizados
‚îÇ   ‚îú‚îÄ‚îÄ setup/                   # üîß Configuraci√≥n inicial
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ setup-gcp.sh         # Setup completo de GCP
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ initialize_vector_store.py  # Indexar portfolio
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ start-local.sh       # Desarrollo local
‚îÇ   ‚îî‚îÄ‚îÄ dev/                     # üõ†Ô∏è Desarrollo y debugging
‚îÇ       ‚îî‚îÄ‚îÄ query_vectors.sh     # Explorar vector store
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ portfolio.yaml           # Knowledge base principal
‚îÇ
‚îú‚îÄ‚îÄ tests/                       # Tests unitarios
‚îú‚îÄ‚îÄ docs/                        # Documentaci√≥n t√©cnica
‚îú‚îÄ‚îÄ Dockerfile                   # Imagen Docker optimizada
‚îú‚îÄ‚îÄ cloudbuild.yaml             # CI/CD con Cloud Build
‚îú‚îÄ‚îÄ requirements.txt             # Dependencias Python
‚îî‚îÄ‚îÄ README.md                   # Este archivo
```

## üîß Desarrollo Local

```bash
# M√©todo r√°pido
./scripts/setup/start-local.sh

# En otro terminal
python3 -m http.server 3000
# Abrir: http://localhost:3000/test-local.html
```

## üìù API Endpoints

### Swagger UI
- **URL**: `https://your-url/docs`
- **Autenticaci√≥n**: Bearer token requerido

### POST /api/v1/chat
Enviar mensaje al chatbot

**Request:**
```json
{
  "message": "¬øCu√°l es tu experiencia con Python?",
  "session_id": "optional-session-id",
  "user_type": "IT"
}
```

**Response:**
```json
{
  "message": "Tengo m√°s de 10 a√±os de experiencia con Python...",
  "sources": [
    {
      "type": "experience",
      "content_preview": "Empresa: InAdvance...",
      "metadata": {...}
    }
  ],
  "session_id": "...",
  "timestamp": "2025-01-15T10:30:00",
  "model": "gemini-2.5-flash"
}
```

### GET /api/v1/health
Health check del servicio

**Response:**
```json
{
  "status": "healthy",
  "version": "1.0.0",
  "timestamp": "2025-01-15T10:30:00"
}
```

### GET /api/v1/analytics
M√©tricas y analytics del chatbot

**Response:**
```json
{
  "total_sessions": 150,
  "total_messages": 450,
  "avg_session_duration": "5m 30s",
  "top_questions": [...],
  "user_types": {...}
}
```

## üß™ Testing

```bash
# Tests unitarios
pytest tests/

# Test manual del RAG
python -c "
from app.services.rag_service import RAGService
import asyncio

async def test():
    service = RAGService()
    result = await service.generate_response('¬øCu√°l es tu experiencia?')
    print(result)

asyncio.run(test())
"
```

## üîí Seguridad

- ‚úÖ **CORS** configurado para dominios espec√≠ficos
- ‚úÖ **Rate limiting** en endpoints
- ‚úÖ **Validaci√≥n** de inputs con Pydantic
- ‚úÖ **Secrets** en Google Secret Manager
- ‚úÖ **Usuario no-root** en Docker
- ‚úÖ **Logs seguros** (sin informaci√≥n sensible)

## üé® Personalizaci√≥n

### Modificar el System Prompt
Editar `app/services/rag_service.py`:
```python
def _create_system_prompt(self) -> PromptTemplate:
    template = """Tu prompt personalizado aqu√≠..."""
    ...
```

### Actualizar Portfolio
```bash
# 1. Editar tu portfolio
nano data/portfolio.yaml

# 2. Re-indexar vectores
python scripts/setup/initialize_vector_store.py

# 3. Re-deploy autom√°tico
git add . && git commit -m "update portfolio" && git push
```

## üìö Tech Stack

### Backend & AI
- **Framework**: FastAPI 0.115+ (Python 3.11)
- **LLM**: Gemini 2.5 Flash (~1-2s respuesta)
- **Embeddings**: HuggingFace sentence-transformers (all-MiniLM-L6-v2, 384-dim, local)
- **Vector DB**: pgvector 0.5+ en PostgreSQL 15 (Cloud SQL)
- **RAG Framework**: LangChain 0.3+

### Infrastructure (GCP)
- **Compute**: Cloud Run (1GB RAM, 1 vCPU, europe-west1)
- **Database**: Cloud SQL (PostgreSQL + pgvector, f1-micro)
- **Registry**: Artifact Registry (europe-west1)
- **Build**: Cloud Build (CI/CD autom√°tico)

### Development
- **Containerization**: Docker (multi-stage build)
- **Testing**: pytest
- **CI/CD**: Cloud Build con triggers autom√°ticos

## ‚ö° Performance

```
Latencia t√≠pica: ~1.5-2 segundos (end-to-end)
  - Embedding query: ~50ms (local)
  - Vector search: ~20ms (pgvector)
  - LLM generation: ~1-2s (Gemini)
  - Total: ~1.5-2s ‚úÖ

Throughput: 30-50 requests/minuto
Vector store: 70 chunks, 384-dim embeddings
```

## üìÑ Licencia

Este proyecto est√° bajo la licencia MIT. Ver `LICENSE` para m√°s detalles.

## üë§ Autor

**√Ålvaro Maldonado**
- Website: https://almapi.dev
- LinkedIn: https://linkedin.com/in/almapidev
- Email: readme.md@almapi.dev

---

**Made with ‚ù§Ô∏è using AI**
